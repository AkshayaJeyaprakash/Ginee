{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article(filedata):\n",
    "    article = filedata.split(\". \")\n",
    "    sentences = []\n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "    sentences =  read_article(file_name)\n",
    "    print(sentences)\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    # print(\"Indexes of top ranked_sentence order are \", ranked_sentence)\n",
    "    for i in range(top_n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "    print(\"\\n\\nSummarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a rapidly evolving field that involves the development of intelligent machines that can perform tasks that typically require human intelligence\n",
      "This includes natural language processing, computer vision, and decision-making\n",
      "AI is used in a wide range of applications, such as autonomous vehicles, chatbots, and image recognition software\n",
      "Machine learning, a subset of AI, is a method of teaching machines to learn from data without being explicitly programmed\n",
      "Deep learning, another subset of AI, involves the use of artificial neural networks that are modeled after the human brain to perform tasks such as image and speech recognition\n",
      "Despite the many potential benefits of AI, there are also concerns about its impact on employment, privacy, and security\n",
      "As AI continues to evolve and become more advanced, it is important to carefully consider its ethical implications and potential consequences.\n",
      "[['Artificial', 'intelligence', '(AI)', 'is', 'a', 'rapidly', 'evolving', 'field', 'that', 'involves', 'the', 'development', 'of', 'intelligent', 'machines', 'that', 'can', 'perform', 'tasks', 'that', 'typically', 'require', 'human', 'intelligence'], ['This', 'includes', 'natural', 'language', 'processing,', 'computer', 'vision,', 'and', 'decision-making'], ['AI', 'is', 'used', 'in', 'a', 'wide', 'range', 'of', 'applications,', 'such', 'as', 'autonomous', 'vehicles,', 'chatbots,', 'and', 'image', 'recognition', 'software'], ['Machine', 'learning,', 'a', 'subset', 'of', 'AI,', 'is', 'a', 'method', 'of', 'teaching', 'machines', 'to', 'learn', 'from', 'data', 'without', 'being', 'explicitly', 'programmed'], ['Deep', 'learning,', 'another', 'subset', 'of', 'AI,', 'involves', 'the', 'use', 'of', 'artificial', 'neural', 'networks', 'that', 'are', 'modeled', 'after', 'the', 'human', 'brain', 'to', 'perform', 'tasks', 'such', 'as', 'image', 'and', 'speech', 'recognition'], ['Despite', 'the', 'many', 'potential', 'benefits', 'of', 'AI,', 'there', 'are', 'also', 'concerns', 'about', 'its', 'impact', 'on', 'employment,', 'privacy,', 'and', 'security']]\n",
      "\n",
      "\n",
      "Summarize Text: \n",
      " Deep learning, another subset of AI, involves the use of artificial neural networks that are modeled after the human brain to perform tasks such as image and speech recognition. Machine learning, a subset of AI, is a method of teaching machines to learn from data without being explicitly programmed. Artificial intelligence (AI) is a rapidly evolving field that involves the development of intelligent machines that can perform tasks that typically require human intelligence\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Number of sentences the summarized sentence must have: \"))\n",
    "text = \"Artificial intelligence (AI) is a rapidly evolving field that involves the development of intelligent machines that can perform tasks that typically require human intelligence. This includes natural language processing, computer vision, and decision-making. AI is used in a wide range of applications, such as autonomous vehicles, chatbots, and image recognition software. Machine learning, a subset of AI, is a method of teaching machines to learn from data without being explicitly programmed. Deep learning, another subset of AI, involves the use of artificial neural networks that are modeled after the human brain to perform tasks such as image and speech recognition. Despite the many potential benefits of AI, there are also concerns about its impact on employment, privacy, and security. As AI continues to evolve and become more advanced, it is important to carefully consider its ethical implications and potential consequences.\"\n",
    "generate_summary(text ,n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
